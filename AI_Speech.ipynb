{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Install Required Libraries**"
      ],
      "metadata": {
        "id": "gDM7ZZdFKmsJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qAVKQegKjap",
        "outputId": "6f95c6f6-39a3-4065-8ef7-6e90b562377b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (42.0.8)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (2.12.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from emoji) (4.12.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.30)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "!pip install spacy\n",
        "!pip install transformers\n",
        "!pip install PyPDF2\n",
        "!pip install pdfplumber\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install transformers torch scikit-learn\n",
        "!pip install emoji\n",
        "!pip install transformers torch scikit-learn optuna\n",
        "\n",
        "# Download SpaCy model\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "# Download NLTK data\n",
        "import nltk\n",
        "nltk.download('opinion_lexicon')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2. Import Required Libraries**"
      ],
      "metadata": {
        "id": "AIgg1jYErHdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pdfplumber\n",
        "import PyPDF2\n",
        "import spacy\n",
        "import emoji\n",
        "import nltk\n",
        "import torch\n",
        "import optuna\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from nltk.corpus import opinion_lexicon, stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from transformers import pipeline, BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from flask import Flask, render_template, request, redirect, url_for\n",
        "from werkzeug.utils import secure_filename\n",
        "\n",
        "# Ensure NLTK data is downloaded\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('opinion_lexicon')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q2DrwABLbhD",
        "outputId": "1aa9cd6f-7669-4fc9-bc5c-f3d1e0317a3f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package opinion_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3. Data Cleaning**\n",
        "### Preprocesses text for emotion detection by performing:\n",
        "*  Lowercasing\n",
        "*  Removing punctuation\n",
        "*  Lemmatization (converting words to their base form)\n",
        "*  Removing stop words (optional, may affect emotion detection)\n",
        "\n",
        "### Args:\n",
        "      * text (str): The text to be cleaned.\n",
        "      * remove_stop_words (bool, optional): Whether to remove stop words. Defaults to True.\n",
        "\n",
        "### Returns:\n",
        "       str: The cleaned text."
      ],
      "metadata": {
        "id": "ZmX-Ykb5scbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "  text = \"\"\n",
        "  # Check if the file exists (optional, but recommended for robustness)\n",
        "  if not os.path.exists(pdf_path):\n",
        "    raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "\n",
        "  with open(pdf_path, 'rb') as f:\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    for page in range(len(reader.pages)):\n",
        "      text += reader.pages[page].extract_text()  # Use reader.pages[page] instead of reader.getPage(page)\n",
        "  return text\n",
        "\n",
        "def clean_text(text, remove_stop_words=True):\n",
        "\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "\n",
        "  # Download nltk resources if not already installed (prevent errors)\n",
        "  nltk.download('punkt', quiet=True)\n",
        "  nltk.download('wordnet', quiet=True)\n",
        "  nltk.download('stopwords', quiet=True)\n",
        "\n",
        "  # Lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = [lemmatizer.lemmatize(token) for token in text.split()]\n",
        "\n",
        "  if remove_stop_words:\n",
        "    # Remove stop words (optional)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "\n",
        "  return \" \".join(tokens)\n",
        "\n",
        "# Example usage (replace with your actual PDF path)\n",
        "pdf_path = '/content/drive/MyDrive/Dataset/test.pdf'\n",
        "\n",
        "try:\n",
        "  text = extract_text_from_pdf(pdf_path)\n",
        "except FileNotFoundError as e:\n",
        "  print(\"Error: \", e)\n",
        "  exit()\n",
        "\n",
        "cleaned_text = clean_text(text)\n",
        "\n",
        "# Print the extracted and cleaned text\n",
        "print(\"Extracted text:\\n\", text)\n",
        "print(\"\\nCleaned text:\\n\", cleaned_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mob5aBmqRGA4",
        "outputId": "fd6ce8d6-2d0d-4d83-e42f-5d90b5188275"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted text:\n",
            " The Park Bench   \n",
            "The park was a haven of tranquillity  amidst the bustling city. Sunlight filtered through the \n",
            "leaves of the towering oak trees, casting dappled patterns on the grassy ground. A \n",
            "gentle breeze rustled the leaves, creating a soothing melody. On a nearby bench, an \n",
            "elderly woman sat reading a book , her face etched with a serene smile. Her wrinkled \n",
            "hands gently turned the pages, her eyes absorbing the words with quiet focus.  \n",
            "A young girl skipped past, her laughter echoing through the park. Her bright yellow dress \n",
            "fluttered in the wind as she chased a playful butterfly. The woman looked up for a \n",
            "moment, a warm smile gracing her lips as she watched the girl's carefree spirit. A flock \n",
            "of birds chirped merrily, flitting from branch to branch. The air was filled with the sweet \n",
            "fragrance of blooming wildflowers.  \n",
            "A sense of peace and tranquillity  settled over the scene. The worries and anxieties of the \n",
            "world seemed to fade away amidst the park's serene beauty. It was a place of solace, a \n",
            "refuge from the daily grind of life. Here, one could simply sit, breathe in the fresh air, and \n",
            "appreciate the s imple joys of being alive.  \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " The Storm   \n",
            "The sky darkened rapidly, ominous clouds gathering overhead. A strong wind howled \n",
            "through the trees, whipping their branches into a frenzy. The once peaceful park was \n",
            "now a scene of chaos. Leaves swirled around in a whirlwind, and loose branches \n",
            "snapped un der the wind's relentless force.  \n",
            "The playful girl from before was nowhere to be seen. The elderly woman had \n",
            "disappeared from her bench. A sense of fear and anxiety gripped the air. The first \n",
            "raindrops began to fall, heavy and cold. Soon, they turned into a torrent, unleashing a \n",
            "relentless  fury upon the park. The wind screamed like a banshee, tearing at the trees as \n",
            "if to uproot them from the ground.  \n",
            "Lightning flashed across the sky, followed by the deafening roar of thunder. The park, \n",
            "once a haven of tranquillity , had transformed into a battleground of nature's raw power. \n",
            "It was a stark reminder of the unpredictable and sometimes violent forces at play in the \n",
            "world.  \n",
            " \n",
            "\n",
            "Cleaned text:\n",
            " park bench park wa tranquillity amidst bustling city sunlight filtered leaf towering oak tree casting dappled pattern grassy ground gentle breeze rustled leaf creating soothing melody nearby bench elderly woman sat reading book face etched serene smile wrinkled hand gently turned page eye absorbing word quiet focus young girl skipped past laughter echoing park bright yellow dress fluttered wind chased playful butterfly woman looked moment warm smile gracing lip watched girl carefree spirit flock bird chirped merrily flitting branch branch air wa filled sweet fragrance blooming wildflower sense peace tranquillity settled scene worry anxiety world seemed fade away amidst park serene beauty wa place solace refuge daily grind life one could simply sit breathe fresh air appreciate imple joy alive storm sky darkened rapidly ominous cloud gathering overhead strong wind howled tree whipping branch frenzy peaceful park wa scene chaos leaf swirled around whirlwind loose branch snapped un der wind relentless force playful girl wa nowhere seen elderly woman disappeared bench sense fear anxiety gripped air first raindrop began fall heavy cold soon turned torrent unleashing relentless fury upon park wind screamed like banshee tearing tree uproot ground lightning flashed across sky followed deafening roar thunder park tranquillity transformed battleground nature raw power wa stark reminder unpredictable sometimes violent force play world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocesses text for emotion detection by performing:\n",
        " - Lowercasing\n",
        " - Removing punctuation\n",
        " - Lemmatization (converting words to their base form)\n",
        " - Removing stop words (optional)\n",
        " - Handling emojis (optional) - convert to text description or remove\n",
        " - Handling informal language (optional) - replace slang, expand abbreviations\n",
        "\n",
        "### Args:\n",
        "     text (str): The text to be cleaned.\n",
        "     remove_stop_words (bool, optional): Whether to remove stop words. Defaults to True.\n",
        "     handle_emojis (bool, optional): Whether to handle emojis (convert or remove). Defaults to True.\n",
        "     handle_informal (bool, optional): Whether to handle informal language (replace slang, expand abbreviations). Defaults to False.\n",
        "\n",
        "### Returns:\n",
        "     str: The cleaned text."
      ],
      "metadata": {
        "id": "eTTq6TgYuXH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "\n",
        "  text = \"\"\n",
        "  # Check if the file exists (optional, but recommended for robustness)\n",
        "  if not os.path.exists(pdf_path):\n",
        "    raise FileNotFoundError(f\"PDF file not found: {pdf_path}\")\n",
        "\n",
        "  with open(pdf_path, 'rb') as f:\n",
        "    reader = PyPDF2.PdfReader(f)\n",
        "    for page in range(len(reader.pages)):\n",
        "      text += reader.pages[page].extract_text()  # Use reader.pages[page] instead of reader.getPage(page)\n",
        "  return text\n",
        "\n",
        "def clean_text(text, remove_stop_words=True, handle_emojis=True, handle_informal=False):\n",
        "\n",
        "  text = text.lower()\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "\n",
        "  # Download nltk resources if not already installed (prevent errors)\n",
        "  nltk.download('punkt', quiet=True)\n",
        "  nltk.download('wordnet', quiet=True)\n",
        "  nltk.download('stopwords', quiet=True)\n",
        "\n",
        "  # Lemmatization\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  tokens = word_tokenize(text)  # Use word_tokenize for emoji detection\n",
        "\n",
        "  # Handle emojis (optional)\n",
        "  if handle_emojis:\n",
        "    for i in range(len(tokens)):\n",
        "      if emoji.demojize(tokens[i]) != tokens[i]:  # Check if token is an emoji\n",
        "        # Replace emoji with text description (optional)\n",
        "        # tokens[i] = emoji.demojize(tokens[i])  # Uncomment to replace with text description\n",
        "        tokens[i] = \"<EMOJI>\"  # Replace with a placeholder\n",
        "\n",
        "  # Lemmatize and handle stop words\n",
        "  clean_tokens = []\n",
        "  for token in tokens:\n",
        "    clean_token = lemmatizer.lemmatize(token)\n",
        "    if remove_stop_words and clean_token not in stopwords.words('english'):\n",
        "      clean_tokens.append(clean_token)\n",
        "    else:\n",
        "      clean_tokens.append(clean_token)\n",
        "\n",
        "  # Handle informal language (optional)\n",
        "  if handle_informal:\n",
        "    # Replace slang with formal equivalents (e.g., \"gonna\" -> \"going to\")\n",
        "    # Expand abbreviations (e.g., \"LOL\" -> \"Laughing Out Loud\")\n",
        "    # You can implement specific replacements here based on your data\n",
        "    informal_to_formal = {\n",
        "      \"gonna\": \"going to\",\n",
        "      \"lmao\": \"laughing my head off\",\n",
        "      # Add more replacements as needed\n",
        "    }\n",
        "    for i in range(len(clean_tokens)):\n",
        "      if clean_tokens[i] in informal_to_formal:\n",
        "        clean_tokens[i] = informal_to_formal[clean_tokens[i]]\n",
        "\n",
        "  return \" \".join(clean_tokens)\n",
        "\n",
        "# Example usage (replace with your actual PDF path)\n",
        "\n"
      ],
      "metadata": {
        "id": "hQjiV61DSIp6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4. Feature Engineering**\n",
        "1. ***Bag-of-Words (BoW):***\n",
        " This is a classic technique that represents text as a \"bag\" of words, ignoring the order of words but capturing their frequency."
      ],
      "metadata": {
        "id": "kR7OMBIivA7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def bag_of_words(text):\n",
        "  \"\"\"\n",
        "  Extracts bag-of-words features from text.\n",
        "\n",
        "  Args:\n",
        "      text (str): The cleaned text.\n",
        "\n",
        "  Returns:\n",
        "      dict: A dictionary where keys are words and values are their frequencies.\n",
        "  \"\"\"\n",
        "  words = text.split()\n",
        "  return Counter(words)\n"
      ],
      "metadata": {
        "id": "iDFDgtvAS59S"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***2. TF-IDF (Term Frequency-Inverse Document Frequency):*** This technique considers both the word frequency (TF) within a document and its rarity across documents (IDF). It assigns higher weights to words that are frequent within a document but less frequent overall."
      ],
      "metadata": {
        "id": "As_rxMNwvY8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def tfidf_features(cleaned_texts):\n",
        "  \"\"\"\n",
        "  Extracts TF-IDF features from a list of cleaned texts.\n",
        "\n",
        "  Args:\n",
        "      cleaned_texts (list): A list of cleaned text strings.\n",
        "\n",
        "  Returns:\n",
        "      scipy.sparse.csr_matrix: A sparse TF-IDF matrix.\n",
        "  \"\"\"\n",
        "  vectorizer = TfidfVectorizer()\n",
        "  tfidf_matrix = vectorizer.fit_transform(cleaned_texts)\n",
        "  return tfidf_matrix\n"
      ],
      "metadata": {
        "id": "tqgVRJUMUErv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***3. N-Grams:*** This technique captures sequences of words (n-grams) like bigrams (2-word sequences) or trigrams (3-word sequences). These can be helpful for capturing phrases that might be indicative of emotions."
      ],
      "metadata": {
        "id": "9Bx43e0fvjnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import ngrams\n",
        "\n",
        "def ngram_features(text, n=2):\n",
        "  \"\"\"\n",
        "  Extracts n-gram features from text.\n",
        "\n",
        "  Args:\n",
        "      text (str): The cleaned text.\n",
        "      n (int, optional): The n-gram value (e.g., 2 for bigrams). Defaults to 2.\n",
        "\n",
        "  Returns:\n",
        "      list: A list of n-gram tuples.\n",
        "  \"\"\"\n",
        "  tokens = text.split()\n",
        "  return list(ngrams(tokens, n))\n"
      ],
      "metadata": {
        "id": "nZ-dlGErUJba"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***4. Sentiment Lexicons:*** You can leverage existing sentiment lexicons that map words to their sentiment scores (positive, negative, neutral). This can provide additional features for emotion detection."
      ],
      "metadata": {
        "id": "rr0RbnaYvtWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using a sentiment lexicon (replace with your chosen lexicon)\n",
        "def sentiment_lexicon_features(text, lexicon):\n",
        "  \"\"\"\n",
        "  Extracts sentiment features from text using a lexicon.\n",
        "\n",
        "  Args:\n",
        "      text (str): The cleaned text.\n",
        "      lexicon (dict): A dictionary mapping words to sentiment scores.\n",
        "\n",
        "  Returns:\n",
        "      tuple: A tuple containing positive and negative sentiment scores.\n",
        "  \"\"\"\n",
        "  positive_score = 0\n",
        "  negative_score = 0\n",
        "  for word in text.split():\n",
        "    if word in lexicon:\n",
        "      score = lexicon[word]\n",
        "      if score > 0:\n",
        "        positive_score += score\n",
        "      else:\n",
        "        negative_score += score\n",
        "  return positive_score, negative_score\n"
      ],
      "metadata": {
        "id": "MMeztt7-UMjf"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***5. Text Length Features:*** The length of the text (number of words or characters) might be informative for some emotion detection tasks."
      ],
      "metadata": {
        "id": "QCJx7Ezfv1KM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_length_features(text):\n",
        "  \"\"\"\n",
        "  Extracts text length features.\n",
        "\n",
        "  Args:\n",
        "      text (str): The cleaned text.\n",
        "\n",
        "  Returns:\n",
        "      tuple: A tuple containing number of words and characters.\n",
        "  \"\"\"\n",
        "  num_words = len(text.split())\n",
        "  num_chars = len(text)\n",
        "  return num_words, num_chars\n"
      ],
      "metadata": {
        "id": "D0NDnU9pUVyI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Analysis**\n",
        "Analyzes sentiment of cleaned text using VADER and predicts emotion as Positive, Negative, or Neutral."
      ],
      "metadata": {
        "id": "EzqUYFbEw0_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a SentimentIntensityAnalyzer object\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Analyze the sentiment of the cleaned text\n",
        "sentiment_scores = sia.polarity_scores(cleaned_text)\n",
        "\n",
        "# Determine the emotion based on the sentiment scores\n",
        "if sentiment_scores['compound'] >= 0.5:\n",
        "    predicted_emotion = 'Positive'\n",
        "elif sentiment_scores['compound'] <= -0.5:\n",
        "    predicted_emotion = 'Negative'\n",
        "else:\n",
        "    predicted_emotion = 'Neutral'\n",
        "\n",
        "print(\"Predicted Emotion:\", predicted_emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0RzxnCeU89T",
        "outputId": "31287a16-5bd7-4c9d-f875-b4c3a53527cb"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Emotion: Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Model Selection**\n",
        "###  Logistic Regression Model:\n",
        "* Trains a Logistic Regression model on the training embeddings and labels.\n",
        "* Evaluates the model on the validation set using accuracy, precision, recall, and F1 score.\n",
        "\n",
        "### Output:\n",
        "\n",
        "* Prints the evaluation metrics for the Logistic Regression model."
      ],
      "metadata": {
        "id": "AKfPS81mxd_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the text and labels (larger dataset)\n",
        "texts = [\n",
        "    \"The park bench was a place of tranquillity amidst the bustling city.\",\n",
        "    \"Suddenly, the sky darkened, and an ominous cloud gathered overhead.\",\n",
        "    \"She loved the way the sunlight filtered through the trees.\",\n",
        "    \"A gentle breeze rustled the leaves, creating a soothing melody.\",\n",
        "    \"The bustling city life was far from her mind as she sat on the bench.\",\n",
        "    \"Chaos erupted as the storm hit, with thunder and lightning.\",\n",
        "    \"The peaceful park was now a scene of chaos.\",\n",
        "    \"Birds chirped happily in the calm, sunny park.\",\n",
        "    \"The once serene sky was now a foreboding grey.\",\n",
        "    \"The sound of children playing added to the park's liveliness.\"\n",
        "]\n",
        "labels = [0, 1, 0, 0, 0, 1, 1, 0, 1, 0]  # Corresponding labels\n",
        "\n",
        "# Ensure texts and labels have consistent lengths\n",
        "assert len(texts) == len(labels), \"The number of texts and labels must be the same\"\n",
        "\n",
        "# Load pre-trained BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the texts\n",
        "encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors='pt')\n",
        "\n",
        "# Get BERT embeddings\n",
        "with torch.no_grad():\n",
        "    outputs = model(**encodings)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "# Split data into training and validation sets without stratification\n",
        "train_embeddings, val_embeddings, train_labels, val_labels = train_test_split(\n",
        "    embeddings, labels, test_size=0.1, random_state=42)\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(train_embeddings, train_labels)\n",
        "log_reg_preds = log_reg.predict(val_embeddings)\n",
        "\n",
        "log_reg_acc = accuracy_score(val_labels, log_reg_preds)\n",
        "log_reg_precision, log_reg_recall, log_reg_f1, _ = precision_recall_fscore_support(val_labels, log_reg_preds, average='binary')\n",
        "\n",
        "print(f\"Logistic Regression - Accuracy: {log_reg_acc}, Precision: {log_reg_precision}, Recall: {log_reg_recall}, F1 Score: {log_reg_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEqt_y9ZXTgb",
        "outputId": "f111e668-0b43-4bdc-9090-65be1b956800"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hyperparameter Tuning with Optuna:**\n",
        "\n",
        "* We define an objective function for Optuna to optimize the hyperparameters of the Logistic Regression model.\n",
        "* The objective function tries different values of C (regularization strength) and solver (optimization algorithm).\n",
        "* We run 50 trials to find the best hyperparameters.\n"
      ],
      "metadata": {
        "id": "2d9gUkN238OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
        "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "\n",
        "    model = LogisticRegression(C=C, solver=solver, max_iter=1000)\n",
        "    model.fit(train_embeddings, train_labels)\n",
        "    preds = model.predict(val_embeddings)\n",
        "\n",
        "    return accuracy_score(val_labels, preds)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZavIHwRpelj",
        "outputId": "2cbf5935-783d-4316-ffd2-6760546d43d9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-23 20:49:06,165] A new study created in memory with name: no-name-c18801c8-1a78-4cae-9aa9-438e5a2295b1\n",
            "[I 2024-06-23 20:49:06,248] Trial 0 finished with value: 0.0 and parameters: {'C': 0.0012061147118259553, 'solver': 'sag'}. Best is trial 0 with value: 0.0.\n",
            "[I 2024-06-23 20:49:06,282] Trial 1 finished with value: 1.0 and parameters: {'C': 0.6404103867149268, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,304] Trial 2 finished with value: 0.0 and parameters: {'C': 0.0032858452210571673, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,328] Trial 3 finished with value: 0.0 and parameters: {'C': 0.04632762043744213, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,352] Trial 4 finished with value: 0.0 and parameters: {'C': 0.09112334754777286, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,369] Trial 5 finished with value: 0.0 and parameters: {'C': 8.327192385628265e-05, 'solver': 'saga'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,391] Trial 6 finished with value: 0.0 and parameters: {'C': 1.3894859199593993e-05, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,411] Trial 7 finished with value: 1.0 and parameters: {'C': 32.08861116814153, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,539] Trial 8 finished with value: 1.0 and parameters: {'C': 98.41677664820804, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,573] Trial 9 finished with value: 1.0 and parameters: {'C': 33.187613079984715, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,618] Trial 10 finished with value: 1.0 and parameters: {'C': 0.7803884543883778, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,647] Trial 11 finished with value: 1.0 and parameters: {'C': 3.508661046307902, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,674] Trial 12 finished with value: 1.0 and parameters: {'C': 2.773633640361226, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,702] Trial 13 finished with value: 1.0 and parameters: {'C': 0.4170301143488201, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,731] Trial 14 finished with value: 1.0 and parameters: {'C': 11.521929315544128, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,752] Trial 15 finished with value: 1.0 and parameters: {'C': 0.39982653449195504, 'solver': 'saga'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,766] Trial 16 finished with value: 1.0 and parameters: {'C': 10.986605556556052, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,785] Trial 17 finished with value: 0.0 and parameters: {'C': 0.00726277484757853, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,804] Trial 18 finished with value: 1.0 and parameters: {'C': 3.8944105500397868, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,832] Trial 19 finished with value: 1.0 and parameters: {'C': 51.74381387664381, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,851] Trial 20 finished with value: 0.0 and parameters: {'C': 0.11165435016623607, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,935] Trial 21 finished with value: 1.0 and parameters: {'C': 90.20196659249336, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:06,983] Trial 22 finished with value: 1.0 and parameters: {'C': 16.07655344873116, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,056] Trial 23 finished with value: 1.0 and parameters: {'C': 92.24721887598105, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:49:07,169] Trial 24 finished with value: 1.0 and parameters: {'C': 1.32401522440305, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,223] Trial 25 finished with value: 1.0 and parameters: {'C': 11.232680838571357, 'solver': 'saga'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,324] Trial 26 finished with value: 1.0 and parameters: {'C': 0.2623412945559467, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,341] Trial 27 finished with value: 0.0 and parameters: {'C': 0.012883480273227717, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,360] Trial 28 finished with value: 1.0 and parameters: {'C': 1.940658075663865, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,437] Trial 29 finished with value: 0.0 and parameters: {'C': 0.00043608578584668976, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,489] Trial 30 finished with value: 1.0 and parameters: {'C': 26.989472201816756, 'solver': 'sag'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,511] Trial 31 finished with value: 1.0 and parameters: {'C': 35.821273215903446, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,533] Trial 32 finished with value: 1.0 and parameters: {'C': 6.058138131864198, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,554] Trial 33 finished with value: 1.0 and parameters: {'C': 43.280425880820346, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,574] Trial 34 finished with value: 1.0 and parameters: {'C': 34.4338740997957, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,596] Trial 35 finished with value: 1.0 and parameters: {'C': 93.16332035662218, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,654] Trial 36 finished with value: 0.0 and parameters: {'C': 0.0424199047065291, 'solver': 'saga'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,673] Trial 37 finished with value: 1.0 and parameters: {'C': 7.325154035317559, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,687] Trial 38 finished with value: 0.0 and parameters: {'C': 0.0011292894340986384, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,709] Trial 39 finished with value: 1.0 and parameters: {'C': 0.7039896665575326, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,731] Trial 40 finished with value: 1.0 and parameters: {'C': 19.51867721093564, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,747] Trial 41 finished with value: 1.0 and parameters: {'C': 0.1193961745171484, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,763] Trial 42 finished with value: 1.0 and parameters: {'C': 1.0176517656921011, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,777] Trial 43 finished with value: 1.0 and parameters: {'C': 4.101593481537554, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,792] Trial 44 finished with value: 0.0 and parameters: {'C': 0.015464550107894798, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,820] Trial 45 finished with value: 1.0 and parameters: {'C': 0.168794415647319, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,840] Trial 46 finished with value: 0.0 and parameters: {'C': 1.3482018162081482e-05, 'solver': 'saga'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,872] Trial 47 finished with value: 1.0 and parameters: {'C': 2.2802687521584932, 'solver': 'newton-cg'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,893] Trial 48 finished with value: 1.0 and parameters: {'C': 0.6582361246233555, 'solver': 'liblinear'}. Best is trial 1 with value: 1.0.\n",
            "[I 2024-06-23 20:49:07,923] Trial 49 finished with value: 1.0 and parameters: {'C': 6.7871542238648415, 'solver': 'lbfgs'}. Best is trial 1 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 0.6404103867149268, 'solver': 'newton-cg'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = LogisticRegression(**best_params, max_iter=1000)\n",
        "final_model.fit(train_embeddings, train_labels)\n",
        "final_preds = final_model.predict(val_embeddings)\n",
        "\n",
        "final_acc = accuracy_score(val_labels, final_preds)\n",
        "final_precision, final_recall, final_f1, _ = precision_recall_fscore_support(val_labels, final_preds, average='binary')\n",
        "\n",
        "print(f\"Final Logistic Regression - Accuracy: {final_acc}, Precision: {final_precision}, Recall: {final_recall}, F1 Score: {final_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8VyxaAg2x-c",
        "outputId": "dc8c6281-0adb-44bd-c539-d6154afe3ad5"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Logistic Regression - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cross-Validation:**\n",
        "\n",
        "* We perform 5-fold cross-validation using KFold.\n",
        "* For each fold, we split the data into training and testing sets, train a Logistic Regression model, and compute performance metrics.\n",
        "* We average the metrics across all folds to get a final evaluation."
      ],
      "metadata": {
        "id": "b80uVNs34Gdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_acc, cv_precision, cv_recall, cv_f1 = [], [], [], []\n",
        "\n",
        "for train_index, test_index in kf.split(embeddings):\n",
        "    X_train, X_test = embeddings[train_index], embeddings[test_index]\n",
        "    y_train, y_test = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
        "\n",
        "    model = LogisticRegression(**best_params, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary')\n",
        "\n",
        "    cv_acc.append(acc)\n",
        "    cv_precision.append(precision)\n",
        "    cv_recall.append(recall)\n",
        "    cv_f1.append(f1)\n",
        "    print(f\"Cross-Validation - Accuracy: {sum(cv_acc)/len(cv_acc)}, Precision: {sum(cv_precision)/len(cv_precision)}, Recall: {sum(cv_recall)/len(cv_recall)}, F1 Score: {sum(cv_f1)/len(cv_f1)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmVRbBsR2_4_",
        "outputId": "bdd446f2-80a0-4cae-c720-cc6fee98e144"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation - Accuracy: 0.5, Precision: 1.0, Recall: 0.5, F1 Score: 0.6666666666666666\n",
            "Cross-Validation - Accuracy: 0.75, Precision: 1.0, Recall: 0.75, F1 Score: 0.8333333333333333\n",
            "Cross-Validation - Accuracy: 0.8333333333333334, Precision: 0.6666666666666666, Recall: 0.5, F1 Score: 0.5555555555555555\n",
            "Cross-Validation - Accuracy: 0.875, Precision: 0.5, Recall: 0.375, F1 Score: 0.41666666666666663\n",
            "Cross-Validation - Accuracy: 0.9, Precision: 0.6, Recall: 0.5, F1 Score: 0.5333333333333333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def objective(trial):\n",
        "    C = trial.suggest_float('C', 1e-5, 1e2, log=True)\n",
        "    solver = trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'])\n",
        "\n",
        "    model = LogisticRegression(C=C, solver=solver, max_iter=1000)\n",
        "    model.fit(train_embeddings, train_labels)\n",
        "    preds = model.predict(val_embeddings)\n",
        "\n",
        "    return accuracy_score(val_labels, preds)\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "best_params = study.best_params\n",
        "print(f\"Best hyperparameters: {best_params}\")\n",
        "\n",
        "# Check if the output is best\n",
        "if study.best_trial.value == 1.0:\n",
        "    final_model = LogisticRegression(**best_params, max_iter=1000)\n",
        "    final_model.fit(train_embeddings, train_labels)\n",
        "    final_preds = final_model.predict(val_embeddings)\n",
        "\n",
        "    final_acc = accuracy_score(val_labels, final_preds)\n",
        "    final_precision, final_recall, final_f1, _ = precision_recall_fscore_support(val_labels, final_preds, average='binary')\n",
        "\n",
        "    print(f\"Final Logistic Regression - Accuracy: {final_acc}, Precision: {final_precision}, Recall: {final_recall}, F1 Score: {final_f1}\")\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    cv_acc, cv_precision, cv_recall, cv_f1 = [], [], [], []\n",
        "\n",
        "    for train_index, test_index in kf.split(embeddings):\n",
        "        X_train, X_test = embeddings[train_index], embeddings[test_index]\n",
        "        y_train, y_test = [labels[i] for i in train_index], [labels[i] for i in test_index]\n",
        "\n",
        "        model = LogisticRegression(**best_params, max_iter=1000)\n",
        "        model.fit(X_train, y_train)\n",
        "        preds = model.predict(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(y_test, preds, average='binary')\n",
        "\n",
        "        cv_acc.append(acc)\n",
        "        cv_precision.append(precision)\n",
        "        cv_recall.append(recall)\n",
        "        cv_f1.append(f1)\n",
        "\n",
        "    print(f\"Cross-Validation - Accuracy: {sum(cv_acc)/len(cv_acc)}, Precision: {sum(cv_precision)/len(cv_precision)}, Recall: {sum(cv_recall)/len(cv_recall)}, F1 Score: {sum(cv_f1)/len(cv_f1)}\")\n",
        "else:\n",
        "    print(\"The best hyperparameters did not yield the highest accuracy. Further investigation may be needed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWULcewL3pol",
        "outputId": "50665afc-b214-40cf-adf4-9a969f6725c4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-06-23 20:53:09,052] A new study created in memory with name: no-name-e22e5147-d985-4de6-b83b-55eb7caf5106\n",
            "[I 2024-06-23 20:53:09,078] Trial 0 finished with value: 0.0 and parameters: {'C': 0.008179448425842796, 'solver': 'liblinear'}. Best is trial 0 with value: 0.0.\n",
            "[I 2024-06-23 20:53:09,107] Trial 1 finished with value: 0.0 and parameters: {'C': 0.0014748493239140046, 'solver': 'newton-cg'}. Best is trial 0 with value: 0.0.\n",
            "[I 2024-06-23 20:53:09,138] Trial 2 finished with value: 0.0 and parameters: {'C': 0.00011728839403621752, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.0.\n",
            "[I 2024-06-23 20:53:09,159] Trial 3 finished with value: 0.0 and parameters: {'C': 0.012672755416855608, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.0.\n",
            "[I 2024-06-23 20:53:09,197] Trial 4 finished with value: 1.0 and parameters: {'C': 2.632739882493432, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:09,233] Trial 5 finished with value: 1.0 and parameters: {'C': 7.672785188447885, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:09,473] Trial 6 finished with value: 0.0 and parameters: {'C': 0.00033466667749586725, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:53:09,761] Trial 7 finished with value: 1.0 and parameters: {'C': 0.33255125858113976, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:09,854] Trial 8 finished with value: 0.0 and parameters: {'C': 0.008170067112004546, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:09,901] Trial 9 finished with value: 1.0 and parameters: {'C': 15.335245387702576, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,012] Trial 10 finished with value: 1.0 and parameters: {'C': 0.5884426832648508, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,073] Trial 11 finished with value: 1.0 and parameters: {'C': 57.618489524293025, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,171] Trial 12 finished with value: 1.0 and parameters: {'C': 1.3967132148667654, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,290] Trial 13 finished with value: 1.0 and parameters: {'C': 8.12268807438887, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,343] Trial 14 finished with value: 1.0 and parameters: {'C': 0.1420451974828105, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,386] Trial 15 finished with value: 1.0 and parameters: {'C': 3.5861829728431824, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,451] Trial 16 finished with value: 1.0 and parameters: {'C': 34.01647979926765, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,606] Trial 17 finished with value: 0.0 and parameters: {'C': 0.07003233265615273, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,690] Trial 18 finished with value: 0.0 and parameters: {'C': 2.1934920373108523e-05, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:10,853] Trial 19 finished with value: 1.0 and parameters: {'C': 2.9885219355037917, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:11,341] Trial 20 finished with value: 1.0 and parameters: {'C': 71.30162749533125, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:53:11,651] Trial 21 finished with value: 1.0 and parameters: {'C': 0.32990931187684314, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:53:11,987] Trial 22 finished with value: 1.0 and parameters: {'C': 0.8400082355824938, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,071] Trial 23 finished with value: 1.0 and parameters: {'C': 8.416821343615114, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,212] Trial 24 finished with value: 1.0 and parameters: {'C': 0.1590936599085025, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,240] Trial 25 finished with value: 0.0 and parameters: {'C': 0.028786704753526526, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,272] Trial 26 finished with value: 1.0 and parameters: {'C': 2.801014084635717, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,315] Trial 27 finished with value: 1.0 and parameters: {'C': 19.848858171827672, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,352] Trial 28 finished with value: 1.0 and parameters: {'C': 0.36870052760151434, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,377] Trial 29 finished with value: 1.0 and parameters: {'C': 1.3114740808637375, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,439] Trial 30 finished with value: 0.0 and parameters: {'C': 0.03537447317487731, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,465] Trial 31 finished with value: 1.0 and parameters: {'C': 15.161178602336129, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,498] Trial 32 finished with value: 1.0 and parameters: {'C': 7.19279852352069, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,527] Trial 33 finished with value: 1.0 and parameters: {'C': 86.89228744894645, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,564] Trial 34 finished with value: 1.0 and parameters: {'C': 22.52702675099403, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,604] Trial 35 finished with value: 1.0 and parameters: {'C': 2.8111439375774037, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,633] Trial 36 finished with value: 1.0 and parameters: {'C': 0.17451059979500871, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "[I 2024-06-23 20:53:12,686] Trial 37 finished with value: 0.0 and parameters: {'C': 0.003987927473664745, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,736] Trial 38 finished with value: 1.0 and parameters: {'C': 1.2654525997408286, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:53:12,941] Trial 39 finished with value: 1.0 and parameters: {'C': 0.5261887865062265, 'solver': 'sag'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:12,977] Trial 40 finished with value: 0.0 and parameters: {'C': 0.0005136643059654451, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,080] Trial 41 finished with value: 1.0 and parameters: {'C': 7.04714430367696, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,179] Trial 42 finished with value: 1.0 and parameters: {'C': 0.5138296330861637, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,303] Trial 43 finished with value: 1.0 and parameters: {'C': 4.4362710128355305, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,359] Trial 44 finished with value: 0.0 and parameters: {'C': 0.06532642073785609, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,544] Trial 45 finished with value: 1.0 and parameters: {'C': 35.44134105830648, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,600] Trial 46 finished with value: 1.0 and parameters: {'C': 1.79454621232091, 'solver': 'lbfgs'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,639] Trial 47 finished with value: 1.0 and parameters: {'C': 9.944425942121796, 'solver': 'newton-cg'}. Best is trial 4 with value: 1.0.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "[I 2024-06-23 20:53:13,901] Trial 48 finished with value: 1.0 and parameters: {'C': 0.2365266888355034, 'solver': 'saga'}. Best is trial 4 with value: 1.0.\n",
            "[I 2024-06-23 20:53:13,924] Trial 49 finished with value: 1.0 and parameters: {'C': 0.846044591580741, 'solver': 'liblinear'}. Best is trial 4 with value: 1.0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 2.632739882493432, 'solver': 'newton-cg'}\n",
            "Final Logistic Regression - Accuracy: 1.0, Precision: 1.0, Recall: 1.0, F1 Score: 1.0\n",
            "Cross-Validation - Accuracy: 1.0, Precision: 0.6, Recall: 0.6, F1 Score: 0.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/optimize.py:203: UserWarning: Line Search failed\n",
            "  warnings.warn(\"Line Search failed\")\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}